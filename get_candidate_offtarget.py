#!/usr/bin/env python3

"""
get_candidate_offtarget.py

Function:
1. Read the result files generated by TDOscanner.
2. Extract the 'upstream20bp' sequence from each file.
3. Search for potential off-target sites in the whole genome using multi-processing.
   - Definition: 20bp upstream of NGG or 20bp downstream of CCN.
   - Matches allowed: 0, 1, or 2 mismatches (configurable).
4. Output new files containing off-target statistics appended to the original data.
"""

import argparse
import sys
import os
import multiprocessing
import pysam
from collections import defaultdict
import itertools

# -----------------------------------------------------------------------------
# Utils
# -----------------------------------------------------------------------------

def reverse_complement(seq):
    complement = str.maketrans('ATCGNatcgn', 'TAGCNtagcn')
    return seq.translate(complement)[::-1]

def generate_1mm_variants(seq):
    """Generate all sequences with exactly 1 mismatch."""
    variants = set()
    bases = ['A', 'C', 'G', 'T']
    seq_list = list(seq)
    length = len(seq)
    
    for i in range(length):
        original_char = seq_list[i]
        for b in bases:
            if b != original_char:
                seq_list[i] = b
                variants.add("".join(seq_list))
        seq_list[i] = original_char # restore
    return variants

def generate_2mm_variants(seq):
    """Generate all sequences with exactly 2 mismatches."""
    variants = set()
    bases = ['A', 'C', 'G', 'T']
    length = len(seq)
    
    # Use combinations to pick 2 positions to change
    for i, j in itertools.combinations(range(length), 2):
        char_i = seq[i]
        char_j = seq[j]
        
        # Iterate through possible bases for both positions
        for b1 in bases:
            if b1 == char_i: continue
            for b2 in bases:
                if b2 == char_j: continue
                
                # Construct variant
                new_seq = seq[:i] + b1 + seq[i+1:j] + b2 + seq[j+1:]
                variants.add(new_seq)
    return variants

def parse_input_files(file_list):
    """
    Read input files and collect query sequences.
    Returns: A set of unique sequences to query.
    """
    query_seqs = set()
    print("Reading input files to collect query sequences...")
    for fname in file_list:
        if not os.path.exists(fname):
            print(f"Warning: File {fname} not found.")
            continue
        
        with open(fname, 'r') as f:
            header = f.readline()
            headers = header.strip().split('\t')
            try:
                col_idx = -1
                for i, h in enumerate(headers):
                    if "upstream20bp" in h:
                        col_idx = i
                        break
            except:
                col_idx = -1

            for line in f:
                parts = line.strip().split('\t')
                if len(parts) <= abs(col_idx): continue
                seq = parts[col_idx].upper()
                
                # Filter invalid sequences
                if len(seq) == 20 and 'N' not in seq:
                    query_seqs.add(seq)
    
    print(f"Total unique query sequences to search: {len(query_seqs)}")
    return query_seqs

def scan_chromosome(args):
    """
    Worker function: Scan a single chromosome.
    args: (chrom_name, fasta_path, interesting_seqs_set)
    """
    chrom, fasta_path, target_set = args
    hits = defaultdict(list)
    
    fasta = pysam.FastaFile(fasta_path)
    try:
        seq = fasta.fetch(chrom).upper()
    except:
        return hits
    
    seq_len = len(seq)
    
    # ---------------------------------------------------------
    # 1. Forward Strand Logic (Look for [20bp] + NGG)
    # ---------------------------------------------------------
    # pos is the index of the first 'G' in 'NGG'
    pos = 0
    while True:
        pos = seq.find('GG', pos)
        if pos == -1: break
        
        # PAM is NGG. 'GG' is at pos, pos+1.
        # N is at pos-1.
        # 20bp target ends at pos-2. 
        # 20bp target starts at pos-1 - 20 = pos - 21.
        
        start_idx = pos - 21
        if start_idx >= 0:
            candidate = seq[start_idx : start_idx + 20]
            if candidate in target_set:
                # 1-based coords
                loc_str = f"{chrom}:{start_idx+1}-{start_idx+20}:+"
                hits[candidate].append(loc_str)
        
        pos += 1

    # ---------------------------------------------------------
    # 2. Reverse Strand Logic (Look for CCN + [20bp])
    # ---------------------------------------------------------
    # pos is the index of the first 'C' in 'CC'
    pos = 0
    while True:
        pos = seq.find('CC', pos)
        if pos == -1: break
        
        # CCN starts at pos.
        # CC at pos, pos+1. N at pos+2.
        # 20bp target starts at pos+3.
        # 20bp target ends at pos+3+20 = pos+23.
        
        start_idx = pos + 3
        end_idx = pos + 23
        
        if end_idx <= seq_len:
            raw_chunk = seq[start_idx : end_idx]
            # Convert to spacer sequence (Reverse Complement)
            candidate = reverse_complement(raw_chunk)
            
            if candidate in target_set:
                loc_str = f"{chrom}:{start_idx+1}-{end_idx}:-"
                hits[candidate].append(loc_str)
        
        pos += 1

    return hits

# -----------------------------------------------------------------------------
# Main Class
# -----------------------------------------------------------------------------

class OffTargetScanner:
    def __init__(self, fasta_path, input_files, max_mismatch):
        self.fasta = fasta_path
        self.max_mismatch = max_mismatch
        self.target_files = {
            'gene_t1': "output_gene_type1.txt",
            'gene_t2': "output_gene_type2.txt",
            'rna_t1': "output_matureRNA_type1.txt",
            'rna_t2': "output_matureRNA_type2.txt"
        }
        if not input_files:
            self.inputs = [f for f in self.target_files.values() if os.path.exists(f)]
        else:
            self.inputs = input_files

    def run(self):
        # 1. Collect Queries
        raw_queries = parse_input_files(self.inputs)
        if not raw_queries:
            print("No valid queries found. Exiting.")
            sys.exit(0)
        
        # 2. Build Search Set
        print(f"Generating variants (Max Mismatch = {self.max_mismatch})...")
        search_set = set()
        
        for q in raw_queries:
            # MM0
            search_set.add(q)
            
            # MM1
            if self.max_mismatch >= 1:
                search_set.update(generate_1mm_variants(q))
            
            # MM2
            if self.max_mismatch >= 2:
                search_set.update(generate_2mm_variants(q))
        
        print(f"Total sequences in search index (Queries + Variants): {len(search_set)}")
        if self.max_mismatch >= 2 and len(search_set) > 10000000:
            print("Warning: Large search set size. This may require significant RAM.")
        
        # 3. Multiprocessing Genome Scan
        print("Scanning genome (this may take a while)...")
        with pysam.FastaFile(self.fasta) as f:
            chroms = f.references
        
        pool_args = [(chrom, self.fasta, search_set) for chrom in chroms]
        
        # Use 75% of CPUs
        n_cpu = max(1, int(multiprocessing.cpu_count() * 0.75))
        print(f"Using {n_cpu} threads.")
        
        global_hits = defaultdict(list)
        
        with multiprocessing.Pool(n_cpu) as pool:
            for chrom_hits in pool.imap_unordered(scan_chromosome, pool_args):
                for seq, locs in chrom_hits.items():
                    global_hits[seq].extend(locs)
        
        print("Genome scan complete. Aggregating results...")
        
        # 4. Process outputs
        self.write_outputs(global_hits)
        print("All done.")

    def format_locations(self, loc_list):
        """Format location list based on count threshold (<= 50)."""
        count = len(loc_list)
        if count == 0:
            return "0", "-"
        elif count > 50:
            return str(count), "-"
        else:
            return str(count), ";".join(loc_list)

    def write_outputs(self, global_hits):
        # Construct header suffix based on mismatch limit
        header_suffix = ""
        for i in range(self.max_mismatch + 1):
            header_suffix += f"\tMM{i}_Count\tMM{i}_Locations"
        header_suffix += "\n"
        
        # Pre-calculate empty string for invalid rows to avoid recalc inside loop
        # Each mismatch level adds 2 columns: Count and Location.
        empty_cols = ("\t0\t-" * (self.max_mismatch + 1))
        
        for fname in self.inputs:
            print(f"Processing results for {fname}...")
            out_name = os.path.splitext(fname)[0] + "_w_offtarget.txt"
            
            with open(fname, 'r') as fin, open(out_name, 'w') as fout:
                # Header
                header = fin.readline().strip()
                fout.write(header + header_suffix)
                
                # Detect column index for upstream20bp
                cols = header.split('\t')
                try:
                    c_idx = -1
                    for i, c in enumerate(cols):
                        if "upstream20bp" in c:
                            c_idx = i
                            break
                    if c_idx == -1: c_idx = -1 
                except:
                    c_idx = -1

                for line in fin:
                    line = line.strip()
                    parts = line.split('\t')
                    if not parts: continue
                    
                    try:
                        query = parts[c_idx].upper()
                    except IndexError:
                        # Handle missing column or malformed line
                        fout.write(line + empty_cols + "\n")
                        continue
                        
                    if 'N' in query or len(query) != 20:
                        fout.write(line + empty_cols + "\n")
                        continue
                    
                    # Construct output line
                    result_line = line
                    
                    # Check for MM0, MM1, MM2 sequentially
                    for mm_level in range(self.max_mismatch + 1):
                        current_hits = []
                        
                        if mm_level == 0:
                            # Direct lookup
                            if query in global_hits:
                                current_hits = global_hits[query]
                        elif mm_level == 1:
                            # Re-generate variants to lookup their hits
                            variants = generate_1mm_variants(query)
                            for v in variants:
                                if v in global_hits:
                                    current_hits.extend(global_hits[v])
                        elif mm_level == 2:
                            # Re-generate variants to lookup their hits
                            variants = generate_2mm_variants(query)
                            for v in variants:
                                if v in global_hits:
                                    current_hits.extend(global_hits[v])
                        
                        count_str, loc_str = self.format_locations(current_hits)
                        result_line += f"\t{count_str}\t{loc_str}"
                    
                    fout.write(result_line + "\n")
            
            print(f"Written: {out_name}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Find candidate CRISPR off-targets for TDOscanner results")
    parser.add_argument("fasta", help="Reference Genome FASTA file")
    parser.add_argument("files", nargs='*', help="Input result files (optional)")
    parser.add_argument("-m", "--mismatch", type=int, choices=[0, 1, 2], default=1, 
                        help="Maximum mismatches allowed (0, 1, or 2). Default: 1")
    
    args = parser.parse_args()
    
    scanner = OffTargetScanner(args.fasta, args.files, args.mismatch)
    scanner.run()
